# üéôÔ∏è Real-Time Live Voice Translation System
### Final Year AI Project ‚Äî Fine-Tuned Neural Machine Translation

---

## üóÇÔ∏è Project Structure

```
live-voice-translator/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app.py              ‚Üê FastAPI REST + WebSocket server
‚îÇ   ‚îú‚îÄ‚îÄ translator.py       ‚Üê Translation engine (Helsinki-NLP MarianMT)
‚îÇ   ‚îú‚îÄ‚îÄ speech_to_text.py   ‚Üê STT using SpeechRecognition / Whisper
‚îÇ   ‚îú‚îÄ‚îÄ text_to_speech.py   ‚Üê TTS using gTTS / pyttsx3
‚îÇ   ‚îú‚îÄ‚îÄ training.py         ‚Üê Fine-tuning pipeline (real + simulated)
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py         ‚Üê BLEU score evaluation
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html          ‚Üê Main UI
‚îÇ   ‚îú‚îÄ‚îÄ style.css           ‚Üê Dark glassmorphism design
‚îÇ   ‚îî‚îÄ‚îÄ script.js           ‚Üê Web Speech API + fetch/WebSocket logic
‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îú‚îÄ‚îÄ dataset_generator.py ‚Üê Synthetic 1500-pair generator
‚îÇ   ‚îú‚îÄ‚îÄ translations.json    ‚Üê Generated dataset (JSON)
‚îÇ   ‚îî‚îÄ‚îÄ translations.jsonl   ‚Üê Generated dataset (JSONL/fine-tuning format)
‚îú‚îÄ‚îÄ documentation/
‚îÇ   ‚îî‚îÄ‚îÄ report.md           ‚Üê Full academic report
‚îî‚îÄ‚îÄ README.md
```

---

## ‚öôÔ∏è Setup (VS Code Terminal)

### Step 1 ‚Äî Install Python dependencies
```bash
cd live-voice-translator/backend
pip install -r requirements.txt
```

> **Note on PyAudio (microphone):**
> - **Windows:** `pip install pipwin && pipwin install pyaudio`
> - **macOS:** `brew install portaudio && pip install pyaudio`
> - **Linux:** `sudo apt install portaudio19-dev && pip install pyaudio`

---

### Step 2 ‚Äî Generate the dataset
```bash
cd live-voice-translator/dataset
python dataset_generator.py
```
Output: `translations.json` and `translations.jsonl` (1500 pairs)

---

### Step 3 ‚Äî Run the simulated fine-tuning
```bash
cd live-voice-translator/backend
python training.py --language french
# All languages:
python training.py --all
```
Output: Training loss curves, BLEU scores, checkpoint saved to `models/`

---

### Step 4 ‚Äî Evaluate
```bash
python evaluate.py --all
```
Output: BLEU-1 through BLEU-4, before/after comparison, sample translations

---

### Step 5 ‚Äî Start the backend
```bash
python app.py
# Or:
uvicorn app:app --reload --port 8000
```
Backend runs at: `http://127.0.0.1:8000`
API Docs: `http://127.0.0.1:8000/docs`

---

### Step 6 ‚Äî Open the frontend
Open `frontend/index.html` directly in Chrome (recommended) or VS Code Live Server.

> **Note:** Use **Google Chrome** for Web Speech API microphone support.

---

## üî¨ Fine-Tuning Explanation

| Hyperparameter | Value | Rationale |
|---|---|---|
| Epochs | 3 | Prevents overfitting on 1500 samples |
| Batch size | 8 | Fits 4‚Äì8 GB RAM; stable gradient updates |
| Learning rate | 2e-5 | Standard for fine-tuning pre-trained transformers |
| Max token length | 128 | Covers 99% of sentences; limits memory usage |
| Weight decay | 0.01 | L2 regularisation, prevents weight explosion |
| Warmup steps | 50 | Linear LR warm-up stabilises early training |
| Train/Val split | 85/15 | Industry standard for small datasets |

**Base model:** [Helsinki-NLP/opus-mt-en-{hi/de/fr/es}](https://huggingface.co/Helsinki-NLP)
These are MarianMT transformer models trained on OPUS corpus data.

**Fine-tuning strategy:** Domain adaptation ‚Äî the base model already knows translation grammar; we fine-tune it on our 6 domain-specific datasets to improve accuracy on: medical, technical, travel, education, and business vocabulary.

---

## üìä Expected BLEU Results

| Language | Baseline | Fine-Tuned | Improvement |
|---|---|---|---|
| French | 28.3 | 38.5 | +10.2 |
| Spanish | 28.3 | 37.2 | +8.9 |
| German | 28.3 | 37.8 | +9.5 |
| Hindi | 28.3 | 36.9 | +8.6 |

---

## üåê API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| GET | `/health` | Health check |
| GET | `/languages` | List supported languages |
| GET | `/model-info` | Training metadata |
| POST | `/translate` | Translate text |
| POST | `/translate-audio` | Audio ‚Üí STT ‚Üí translate ‚Üí TTS |
| WS | `/ws/translate` | Real-time WebSocket stream |

---

## üß∞ Technologies Used

- **Backend:** Python 3.10+, FastAPI, Uvicorn
- **ML Model:** Helsinki-NLP MarianMT (HuggingFace Transformers)
- **Fine-Tuning:** HuggingFace Trainer API, PyTorch
- **STT:** SpeechRecognition (Google Web Speech API) / Whisper
- **TTS:** gTTS (Google Text-to-Speech)
- **Frontend:** HTML5, CSS3, Vanilla JS, Web Speech API
- **Dataset:** Custom synthetic JSONL (1500 pairs, 6 domains, 4 languages)
- **Evaluation:** BLEU-1 through BLEU-4 (sacrebleu)

---

## ‚úÖ Academic Checklist

- [x] 1500 synthetic translation pairs generated
- [x] JSONL format (fine-tuning standard)
- [x] 6 domains covered (daily, travel, medical, business, education, technical)
- [x] 4 language pairs (EN‚ÜíHI, EN‚ÜíDE, EN‚ÜíFR, EN‚ÜíES)
- [x] Fine-tuning pipeline with epochs, batch size, LR, weight decay
- [x] BLEU score before/after comparison
- [x] Real-time voice capture (Web Speech API)
- [x] Translation API (FastAPI + WebSocket)
- [x] Text-to-speech output (gTTS)
- [x] Latency and confidence metrics displayed
- [x] Full documentation
